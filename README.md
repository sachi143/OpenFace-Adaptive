# OpenFace-Adaptive ğŸ­

**Robust Multimodal Emotion Recognition via Reliability-Aware Gating and Cross-Modal Attention**

> ğŸ“„ *Submitted at FG 2026 (under review)*

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ¯ Overview

OpenFace-Adaptive is a robust multimodal emotion recognition framework designed for **"in-the-wild" deployments** where sensor failures are common. The system introduces:

- **Reliability-Aware Gating (RAG)**: Dynamically assigns trust scores to each modality, suppressing noisy signals
- **Heterogeneous Graph Transformer**: Models cross-modal dependencies with attention-based fusion
- **Edge-Ready Deployment**: Quantized to 2.5 MB for real-time inference on resource-constrained devices

## ğŸ“Š Results

| Metric | Score |
|--------|-------|
| **7-Class Accuracy** | 44.0% |
| **Binary Accuracy** | 72.1% |
| **Robustness Gain** | +3.6% under noise |
| **Model Size** | 7.9 MB (2.5 MB quantized) |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenFace   â”‚    â”‚   COVAREP   â”‚    â”‚   GloVe     â”‚
â”‚  (713-d)    â”‚    â”‚   (74-d)    â”‚    â”‚   (300-d)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reliability  â”‚    â”‚ Reliability  â”‚    â”‚              â”‚
â”‚   Gate (Î±v)  â”‚    â”‚   Gate (Î±a)  â”‚    â”‚   (Text)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Heterogeneous Graph    â”‚
              â”‚     Transformer        â”‚
              â”‚   (3 layers, 4 heads)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   7-Class Classifier   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/OpenFace-Adaptive.git
cd OpenFace-Adaptive

# Create conda environment
conda env create -f environment.yaml
conda activate openface_adaptive

# Install dependencies
pip install torch transformers librosa pyaudio speechrecognition
```

### Training

```bash
# Run full experiment suite (Baseline, Ablations, Robustness tests)
python experiment_runner.py
```

### Live Demo

```bash
# Real-time emotion recognition with webcam + microphone
python live_demo.py
```

### Evaluation

```bash
# Generate confusion matrix
python generate_confusion_matrix.py

# Verify binary accuracy
python verify_binary.py

# Generate trust score visualization
python plot_trust.py
```

## ğŸ“ Project Structure

```
OpenFace-Adaptive/
â”œâ”€â”€ model.py                 # Core model architecture
â”œâ”€â”€ data_loader.py           # CMU-MOSEI dataset loader
â”œâ”€â”€ experiment_runner.py     # Training & evaluation pipeline
â”œâ”€â”€ live_demo.py             # Real-time webcam demo
â”œâ”€â”€ generate_confusion_matrix.py  # Evaluation visualization
â”œâ”€â”€ verify_binary.py         # Binary accuracy computation
â”œâ”€â”€ plot_trust.py            # Trust score visualization
â”œâ”€â”€ quantize.py              # INT8 quantization script
â”œâ”€â”€ preprocess_mosei.py      # Data preprocessing
â”œâ”€â”€ environment.yaml         # Conda environment
â”œâ”€â”€ results/                 # Model checkpoints
â”‚   â””â”€â”€ model_baseline.pth
â”œâ”€â”€ paper/                   # LaTeX source for FG 2026 paper
â”‚   â””â”€â”€ latexsource/
â”‚       â””â”€â”€ submission.pdf
â””â”€â”€ OpenFace_2.2.0/          # OpenFace toolkit (not included)
```

## ğŸ“¦ Model Weights

| Model | Size | Download |
|-------|------|----------|
| Full Model | 7.9 MB | `results/model_baseline.pth` |
| Quantized (INT8) | 2.5 MB | `openface_adaptive_quantized.pth` |

## ğŸ“ Citation

If you find this work useful, please cite our paper:

```bibtex
@inproceedings{openface_adaptive2026,
  title={OpenFace-Adaptive: Robust Multimodal Emotion Recognition via Reliability-Aware Gating and Cross-Modal Attention},
  author={[Authors]},
  booktitle={IEEE International Conference on Automatic Face and Gesture Recognition (FG)},
  year={2026}
}
```

## ğŸ” Access & Collaboration

This is a **private repository** for research purposes. If you are interested in:
- Accessing the full codebase
- Obtaining pre-trained model weights
- Collaborating on this research

Please contact us via:
- ğŸ“§ Email: sairam.chennaka@gmail.com
- ğŸ”— GitHub: Open an issue on this repository

**For reviewers**: Full code, model weights, and dataset access will be provided upon request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [CMU-MOSEI](https://www.amir-zadeh.com/datasets) dataset
- [OpenFace 2.0](https://github.com/TadasBaltrusaitis/OpenFace) toolkit
- [COVAREP](https://github.com/covarep/covarep) audio features
